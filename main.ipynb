{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from utils import *\n",
    "from model import *\n",
    "from dataset import *\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "model_file = \"./data/kowiki.model\" \n",
    "\n",
    "# SentencePiece 모델 로드\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(model_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A  label\n",
       "0                   12시 땡!          하루가 또 가네요.      0\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_name = 'ChatbotData'\n",
    "csv_path = './data/ChatbotData.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q seq_max_len: 33\n",
      "A seq_max_len: 43\n",
      "Original Text: 12시 땡!\n",
      "Tokens: ['▁12', '시', '▁', '땡', '!']\n",
      "IDs: [196, 3613, 3587, 6308, 4232, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Original Text: 1지망 학교 떨어졌어\n",
      "Tokens: ['▁1', '지', '망', '▁학교', '▁떨어', '졌', '어']\n",
      "IDs: [7, 3601, 3946, 1176, 1522, 3940, 3624, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Original Text: 3박4일 놀러가고 싶다\n",
      "Tokens: ['▁3', '박', '4', '일', '▁놀', '러', '가', '고', '▁싶', '다']\n",
      "IDs: [49, 3905, 3656, 3620, 2356, 3716, 3599, 3600, 2636, 3589, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Original Text: 3박4일 정도 놀러가고 싶다\n",
      "Tokens: ['▁3', '박', '4', '일', '▁정도', '▁놀', '러', '가', '고', '▁싶', '다']\n",
      "IDs: [49, 3905, 3656, 3620, 1121, 2356, 3716, 3599, 3600, 2636, 3589, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Original Text: PPL 심하네\n",
      "Tokens: ['▁P', 'P', 'L', '▁심', '하', '네']\n",
      "IDs: [440, 3870, 3915, 413, 3596, 3857, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#시퀀스 max 길이 찾기\n",
    "seq_max_len = 0\n",
    "for line in list(df['Q'].values):\n",
    "    leng = len(sp.encode_as_ids(line))\n",
    "    if seq_max_len < leng:\n",
    "        seq_max_len = leng\n",
    "print(\"Q seq_max_len:\", seq_max_len)\n",
    "\n",
    "\n",
    "for line in list(df['A'].values):\n",
    "    leng = len(sp.encode_as_ids(line))\n",
    "    if seq_max_len < leng:\n",
    "        seq_max_len = leng\n",
    "print(\"A seq_max_len:\", seq_max_len)\n",
    "\n",
    "#학습데이터 Vocab 적용해보기\n",
    "ids_stack = []\n",
    "for line in list(df['Q'][:5].values):\n",
    "    pieces = sp.encode_as_pieces(line)\n",
    "    ids = sp.encode_as_ids(line)\n",
    "    ids += (seq_max_len-len(ids))*[0]\n",
    "    ids_stack.append(ids)\n",
    "    print(\"Original Text:\", line)\n",
    "    print(\"Tokens:\", pieces)\n",
    "    print(\"IDs:\", ids)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset length: 10640\n",
      "val_dataset length: 1183\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ChatBotDataset(csv_path, seq_max_len)\n",
    "val_dataset = ChatBotDataset(csv_path, seq_max_len, train=False)\n",
    "\n",
    "print(\"train_dataset length:\", len(train_dataset))\n",
    "print(\"val_dataset length:\", len(val_dataset)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled_dot_Attention 계산 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답: tensor([[[1.1807, 2.0000, 2.8193],\n",
      "         [2.8193, 2.0000, 1.1807],\n",
      "         [1.1807, 2.0000, 2.8193]],\n",
      "\n",
      "        [[3.0000, 2.0000, 2.0000],\n",
      "         [3.0000, 2.0000, 2.0000],\n",
      "         [3.0000, 2.0000, 2.0000]]])\n"
     ]
    }
   ],
   "source": [
    "n_dim = 3\n",
    "q = torch.tensor([[[1,2,3],\n",
    "                   [3,2,1],\n",
    "                   [4,5,6]],\n",
    "                  \n",
    "                  [[3,2,2],\n",
    "                   [1,1,1],\n",
    "                   [5,2,4]]], dtype=torch.float32)\n",
    "k = q.transpose(-1,-2)\n",
    "token_ids = torch.tensor([[1,1,0], [1,0,0]])\n",
    "\n",
    "\n",
    "scaled_attention = torch.matmul(q,k) / np.sqrt(n_dim)\n",
    "masked_attention =  making_padding_mask(scaled_attention, token_ids)\n",
    "attention_score = torch.softmax(masked_attention, dim=-1)\n",
    "output = torch.matmul(attention_score, q)\n",
    "print(\"정답:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4208,  0.8233,  0.1114],\n",
       "         [-0.4719,  0.8608,  0.1540],\n",
       "         [-0.5877,  0.9457,  0.2505]],\n",
       "\n",
       "        [[ 0.4391, -0.1292, -0.8138],\n",
       "         [ 0.4391, -0.1292, -0.8138],\n",
       "         [ 0.4391, -0.1292, -0.8138]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#확인할 때 q,k,v의 가중치는 제외하고 확인해볼 것\n",
    "model = ScaledDotProductAttention(3)\n",
    "model(q,q,q,token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "#model hyperparameter\n",
    "model_name = 'transformer_decoderloop'\n",
    "n_seq = seq_max_len\n",
    "n_vocab = sp.vocab_size()\n",
    "# 논문의 절반으로 setting\n",
    "n_dim = 256\n",
    "n_head = 4\n",
    "n_layer = 2\n",
    "\n",
    "# dataloader hyperparameter\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#train, Loss, Optimizer hyperparameter\n",
    "epochs = 100\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(n_seq, n_vocab, n_dim, n_head, n_layer, device=device).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loss_fn, optimizer, save_path, eval_step=1,resume=False, run_id=None):\n",
    "    \n",
    "    wandb.init(\n",
    "        project='Transformer_ChatBot',\n",
    "        name = f'{model_name}_{dataset_name}',\n",
    "        resume=\"allow\" if resume else None,\n",
    "        id=run_id if resume else None,\n",
    "        config={\n",
    "            \"architecture\": model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"lr\": lr,\n",
    "            \"epochs\": epochs,\n",
    "            \"n_seq\": n_seq,\n",
    "            \"n_vocab\": n_vocab,\n",
    "            \"n_dim\": n_dim,\n",
    "            \"n_head\": n_head,\n",
    "            \"n_layer\": n_layer,\n",
    "            \"loss_fn\": \"CrossEntropyLoss\",\n",
    "            \"optimizer\": \"Adam\",\n",
    "        })\n",
    "    \n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    model.train()\n",
    "    best_val_loss = np.inf\n",
    "    # BOS 토큰 ID를 가져옵니다.\n",
    "    bos_token_id = sp.bos_id()\n",
    "    for epoch in tqdm(range(epochs), ascii=True, desc=\"epoch\"):\n",
    "        print()\n",
    "        print(f\"********** epoch{epoch+1} train start **********\")\n",
    "        train_loss = 0\n",
    "        for idx, (q, a) in enumerate(train_dataloader):\n",
    "            q, a = q.to(device), a.to(device)\n",
    "            # a를 bos_a로 변경 (오른쪽 시프트)\n",
    "            bos_a = shift_right(a, bos_token_id)\n",
    "            \n",
    "            # 디코더 루프별로 손실 계산\n",
    "            total_loss = 0.0\n",
    "            pred_lst = []\n",
    "            # 문장 만들 index\n",
    "            indx = np.random.randint(0, len(q))  # 0 ~ batch_size 사이의 숫자 랜덤으로 뽑기\n",
    "            for i in range(n_seq):\n",
    "                # 디코더 입력 업데이트\n",
    "                current_dec_input = torch.cat([bos_a[:, :i + 1], torch.zeros((bos_a.size(0), n_seq - i - 1), device=device, dtype=torch.long)], dim=1)\n",
    "            \n",
    "                # 모델 예측\n",
    "                output = model(q, current_dec_input)\n",
    "            \n",
    "                # 다음 토큰 예측\n",
    "                pred = output[:, i, :]  # 현재 스텝의 출력을 사용\n",
    "                target = a[:, i]  # 현재 스텝의 목표 토큰\n",
    "                pred_lst.append(softmax(pred[indx]).argmax(dim=-1).item())\n",
    "                # 손실 계산\n",
    "                loss = loss_fn(pred, target)\n",
    "                total_loss += loss\n",
    "                \n",
    "            avg_loss = total_loss / n_seq\n",
    "            train_loss += avg_loss.item()\n",
    "        \n",
    "            # 역전파 및 최적화\n",
    "            optimizer.zero_grad()\n",
    "            avg_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if idx % (len(train_dataloader)//3) == 0:\n",
    "                print(\"epoch: {}, loss: {}\".format(epoch+1, avg_loss.item()))\n",
    "                # 문장 만들기\n",
    "                pred_sentc = sp.DecodeIds(pred_lst)\n",
    "                label_sentc = sp.DecodeIds(a[indx].tolist())\n",
    "                q_sentc = sp.DecodeIds(q[indx].tolist())\n",
    "                print(\"Q:\", q_sentc)\n",
    "                print(\"Pred:\", pred_sentc)\n",
    "                print(\"Label:\", label_sentc)  \n",
    "        \n",
    "        print(\"epoch: {}, train_loss: {}\".format(epoch+1, train_loss/len(train_dataloader)))\n",
    "        print(\"********** train end **********\")\n",
    "        \n",
    "        #wandb에 로그 기록\n",
    "        train_metrics = {'train_loss': train_loss/len(train_dataloader)}\n",
    "        wandb.log(train_metrics, step=epoch)\n",
    "        print()\n",
    "        if epoch % eval_step == 0:\n",
    "            with torch.no_grad():\n",
    "                print(\"********** eval start **********\")\n",
    "                model.eval()\n",
    "                val_loss = 0.0\n",
    "                for idx, (q, a) in enumerate(val_dataloader):\n",
    "                    q, a = q.to(device), a.to(device)\n",
    "                    bos_a = shift_right(a, bos_token_id)\n",
    "                    # 디코더 루프별로 손실 계산\n",
    "                    total_loss = 0.0\n",
    "                    pred_lst = []\n",
    "                    # 문장 만들 index\n",
    "                    indx = np.random.randint(0, len(q))  # 0 ~ len(val_dataset) 사이의 숫자 랜덤으로 뽑기\n",
    "                    for i in range(n_seq):\n",
    "                        # 디코더 입력 업데이트\n",
    "                        current_dec_input = torch.cat([bos_a[:, :i + 1], torch.zeros((bos_a.size(0), n_seq - i - 1), device=device, dtype=torch.long)], dim=1)\n",
    "                    \n",
    "                        # 모델 예측\n",
    "                        output = model(q, current_dec_input)\n",
    "                    \n",
    "                        # 다음 토큰 예측\n",
    "                        pred = output[:, i, :]  # 현재 스텝의 출력을 사용\n",
    "                        target = a[:, i]  # 현재 스텝의 목표 토큰\n",
    "                        pred_lst.append(softmax(pred[indx]).argmax(dim=-1).item())\n",
    "                        # 손실 계산\n",
    "                        loss = loss_fn(pred, target)\n",
    "                        total_loss += loss\n",
    "                    \n",
    "                    avg_loss = total_loss / n_seq\n",
    "                    val_loss += avg_loss.item()\n",
    "               \n",
    "                # 문장 만들기\n",
    "                pred_sentc = sp.DecodeIds(pred_lst)\n",
    "                label_sentc = sp.DecodeIds(a[indx].tolist())\n",
    "                q_sentc = sp.DecodeIds(q[indx].tolist())\n",
    "                print(\"Q:\", q_sentc)\n",
    "                print(\"Pred:\", pred_sentc)\n",
    "                print(\"Label:\", label_sentc)  \n",
    "               \n",
    "                avg_val_loss = val_loss / len(val_dataloader)\n",
    "                if best_val_loss > avg_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "                    print(\"\\n****best model saved****\\n\")\n",
    "                \n",
    "                print(\"epoch: {}, val_loss: {}\".format(epoch + 1, avg_val_loss))\n",
    "                val_metrics = {'val_loss': avg_val_loss}\n",
    "                wandb.log(val_metrics, step=epoch)\n",
    "              \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdwkim8155\u001b[0m (\u001b[33mboostcamp-oif\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/Woo/Desktop/kaist/1-1/NLP-Summer/Transformer 구현/wandb/run-20240708_152802-cyjhyuuy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp-oif/Transformer_ChatBot/runs/cyjhyuuy' target=\"_blank\">transformer_decoderloop_ChatbotData</a></strong> to <a href='https://wandb.ai/boostcamp-oif/Transformer_ChatBot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp-oif/Transformer_ChatBot' target=\"_blank\">https://wandb.ai/boostcamp-oif/Transformer_ChatBot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp-oif/Transformer_ChatBot/runs/cyjhyuuy' target=\"_blank\">https://wandb.ai/boostcamp-oif/Transformer_ChatBot/runs/cyjhyuuy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** epoch1 train start **********\n",
      "epoch: 1, loss: 9.61805534362793\n",
      "Q: 친구한테 쌓인 게 안 풀려\n",
      "Pred: 들을 레 배경敗딪 만나ザ라스기의泳 드라마吏뎀峰폴 즐 지도 지도 원칙 원칙 원칙봐봐봐봐봐位 지도 지도 지도 지도 지도 지도隣隣隣隣휴휴휴휴휴휴\n",
      "Label: 대화하면서 얽힌 감정들을 풀어보세요.\n",
      "epoch: 1, loss: 1.9782787561416626\n",
      "Q: 다 알고 있을까?\n",
      "Pred: \n",
      "Label: 다 알 수는 없어요.\n",
      "epoch: 1, loss: 1.5723509788513184\n",
      "Q: 엄마랑 둘이 여행가\n",
      "Pred: 요요요.\n",
      "Label: 좋은 여행이 될 거예요.\n",
      "epoch: 1, loss: 1.4829152822494507\n",
      "Q: 세상에서 제일 쓸데없는 게 짝사랑 같아.\n",
      "Pred: 세 요요요요요.\n",
      "Label: 감정소모가 심하긴 해요.\n",
      "epoch: 1, train_loss: 2.131368714178394\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   1%|1         | 1/100 [08:29<14:00:50, 509.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 1년 넘게 만났는데 지금도 불타올라\n",
      "Pred: 이 요요요요요요.\n",
      "Label: 정열적인 사랑을 하고 있나봐요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 1, val_loss: 1.3439699850584332\n",
      "\n",
      "********** epoch2 train start **********\n",
      "epoch: 2, loss: 1.4544585943222046\n",
      "Q: 알바하는데 같이 일하는 사람 좋아져\n",
      "Pred: 도세세요요요요세요.\n",
      "Label: 용기내서 고백해보세요.\n",
      "epoch: 2, loss: 1.25917649269104\n",
      "Q: 편두통 온다\n",
      "Pred: 하요요요.\n",
      "Label: 잠시 쉬었다 가세요.\n",
      "epoch: 2, loss: 1.0620534420013428\n",
      "Q: 이별을 해야하나봐\n",
      "Pred: 이 해요.\n",
      "Label: 마음이 문제네요.\n",
      "epoch: 2, loss: 1.1690996885299683\n",
      "Q: 오늘부터 짝사랑을 끝내려 합니다.\n",
      "Pred: 들게해 거해요돼요요이요해요.\n",
      "Label: 힘든 결정이었을텐데 맘고생 많았어요.\n",
      "epoch: 2, train_loss: 1.2193384052750593\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   2%|2         | 2/100 [16:51<13:45:09, 505.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 화장 열심히 했는데\n",
      "Pred: 해보괜지이해보세요.\n",
      "Label: 다음에는 픽서를 사용해보세요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 2, val_loss: 1.1186790936871578\n",
      "\n",
      "********** epoch3 train start **********\n",
      "epoch: 3, loss: 1.126986026763916\n",
      "Q: 그노무 카톡.\n",
      "Pred: 락이네해.\n",
      "Label: 연락이 문제죠.\n",
      "epoch: 3, loss: 1.0096713304519653\n",
      "Q: 짝사랑만큼 고통스러운 건 없겠지.\n",
      "Pred: 맛사랑가큼 기 거.요봐네요세요예요.\n",
      "Label: 짝사랑 만큼 감정소모가 큰 건 없을 거예요.\n",
      "epoch: 3, loss: 1.0138709545135498\n",
      "Q: 예전 게임인데 재밌다\n",
      "Pred: 도 도어요.\n",
      "Label: 저도 하고 싶네요.\n",
      "epoch: 3, loss: 1.0430575609207153\n",
      "Q: 손 얼것 같음\n",
      "Pred: 준  해해요.\n",
      "Label: 장갑을 끼세요.\n",
      "epoch: 3, train_loss: 1.0517081946669937\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   3%|3         | 3/100 [25:21<13:40:10, 507.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 항상 나중에 후회해\n",
      "Pred: 이었 수가 더 해 있어요세요.\n",
      "Label: 결정할 때 좀 더 생각하고 해보세요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 3, val_loss: 1.0137381020345186\n",
      "\n",
      "********** epoch4 train start **********\n",
      "epoch: 4, loss: 0.9699960947036743\n",
      "Q: 싸움을 피하는 방법\n",
      "Pred: 해을 해보보세요.\n",
      "Label: 이해하고 배려해보세요.\n",
      "epoch: 4, loss: 0.9304722547531128\n",
      "Q: 미치겠습니다 연락하고 싶어서\n",
      "Pred: 락해 있다을  들겠예요.\n",
      "Label: 연락하고 나면 더 힘들 거예요.\n",
      "epoch: 4, loss: 0.9414264559745789\n",
      "Q: 뜻밖에 연락\n",
      "Pred: 이겠!을요겠네요.\n",
      "Label: 흔들리지 않는게 좋겠어요.\n",
      "epoch: 4, loss: 0.8692339658737183\n",
      "Q: 미세먼지 때문에 짜증나\n",
      "Pred: 음을하랑 싶 거요.\n",
      "Label: 마스크 쓰고 나가세요.\n",
      "epoch: 4, train_loss: 0.9561153932245906\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   4%|4         | 4/100 [33:53<13:34:55, 509.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  ⁇  앞에만 서면 말이 안 나와\n",
      "Pred: 슨는하는 수 마락해보세요.\n",
      "Label: 무슨 말을 할지 연습해보세요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 4, val_loss: 0.9486182802601865\n",
      "\n",
      "********** epoch5 train start **********\n",
      "epoch: 5, loss: 0.9129430055618286\n",
      "Q: 나만 힘든 거였구나\n",
      "Pred: 이 될을보을죠요.\n",
      "Label: 마음이 약해 탈이네요.\n",
      "epoch: 5, loss: 0.9526869058609009\n",
      "Q: 새학기 필기구 좀 사야지\n",
      "Pred: 의가까지해하는세요.\n",
      "Label: 새학기 준비 잘 하세요.\n",
      "epoch: 5, loss: 0.9389668107032776\n",
      "Q: 내일 짝녀랑 영화보러갑니다.\n",
      "Pred: 힘는세어요.\n",
      "Label: 많이 떨리겠어요.\n",
      "epoch: 5, loss: 0.902319610118866\n",
      "Q: 연애는 어떻게 하는 거야\n",
      "Pred: 이 복잡원죠지네세 겠.\n",
      "Label: 마음이 시키는데로 하면 되요.\n",
      "epoch: 5, train_loss: 0.8891291839633874\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   5%|5         | 5/100 [42:20<13:25:03, 508.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 잠 들기가 무서워\n",
      "Pred: 일은한 더 힘아 언를 거예요.요랄게요.\n",
      "Label: 내일은 좀 더 나은 하루일 거예요. 푹 자길 바랄게요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 5, val_loss: 0.9021446610751905\n",
      "\n",
      "********** epoch6 train start **********\n",
      "epoch: 6, loss: 0.8310187458992004\n",
      "Q: 차 기름값이 또 올랐네\n",
      "Pred: 교통해 해해보세요.\n",
      "Label: 대중교통을 이용해주세요.\n",
      "epoch: 6, loss: 0.884208083152771\n",
      "Q: 선풍기 틀어도 더워\n",
      "Pred: 페게 세 그런세면세 떨까요.\n",
      "Label: 카페라도 가서 쉬다 오면 어떨까요\n",
      "epoch: 6, loss: 0.7200881838798523\n",
      "Q: 잘 나갈 때 은퇴해야하나?\n",
      "Pred: 을였보세요.\n",
      "Label: 끝까지 해보세요.\n",
      "epoch: 6, loss: 0.8212496638298035\n",
      "Q: 입 안이 텁텁해\n",
      "Pred: 에 해잊 게가세요.\n",
      "Label: 입을 헹궈보세요.\n",
      "epoch: 6, train_loss: 0.83896290113826\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   6%|6         | 6/100 [51:01<13:22:48, 512.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 제 친구가 술마시면서 잊으려고\n",
      "Pred: 별은 해들이는 것도 좋해보.\n",
      "Label: 이별을 받아들이는 것도 중요해요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 6, val_loss: 0.8707015106552526\n",
      "\n",
      "********** epoch7 train start **********\n",
      "epoch: 7, loss: 0.7749017477035522\n",
      "Q: 좋은 이별을 하려면 어떻게 해야 할까??\n",
      "Pred: 사람별이 요.\n",
      "Label: 좋은 이별은 없어요.\n",
      "epoch: 7, loss: 0.7488871812820435\n",
      "Q: 나 갖고 장난친건가\n",
      "Pred: 에 바랍요.\n",
      "Label: 아니길 바라요.\n",
      "epoch: 7, loss: 0.8151760697364807\n",
      "Q: 밥이 없어\n",
      "Pred: 사랑기어 돼요.\n",
      "Label: 새로운 관계를 만들면 돼요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, loss: 0.76300448179245\n",
      "Q: 너무 너무 억울하다.\n",
      "Pred: 지로 때이네릴세 바랄게요.\n",
      "Label: 억울함이 풀리길 바랄게요.\n",
      "epoch: 7, train_loss: 0.7988019871140668\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   7%|7         | 7/100 [59:40<13:17:47, 514.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 헉\n",
      "Pred: 랐을봐요.\n",
      "Label: 놀랐나봐요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 7, val_loss: 0.8446334851415533\n",
      "\n",
      "********** epoch8 train start **********\n",
      "epoch: 8, loss: 0.7734354734420776\n",
      "Q: 이별한지 이제 일주일째네\n",
      "Pred: 될뎌션 싶겠 바랄게요.\n",
      "Label: 잘 견디고 있길 바랄게요.\n",
      "epoch: 8, loss: 0.7604236006736755\n",
      "Q: 내 여자로 만들기\n",
      "Pred: 은  사랑 게 좋에요.\n",
      "Label: 사랑은 소유하는 게 아니에요.\n",
      "epoch: 8, loss: 0.7462155818939209\n",
      "Q: SD카드 안돼\n",
      "Pred: 연도 재 좋이이보.\n",
      "Label: 다시 새로 사는 게 마음 편해요.\n",
      "epoch: 8, loss: 0.7079250812530518\n",
      "Q: 환기 좀 해야할까?\n",
      "Pred: 일이승세게 좋을요.\n",
      "Label: 매일 환기하는 게 좋대요.\n",
      "epoch: 8, train_loss: 0.7643518640609559\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   8%|8         | 8/100 [1:08:06<13:04:58, 511.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 끝이났네\n",
      "Pred: 맛고생 많았어요.\n",
      "Label: 맘고생 많았어요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 8, val_loss: 0.8234971322511372\n",
      "\n",
      "********** epoch9 train start **********\n",
      "epoch: 9, loss: 0.7661365270614624\n",
      "Q: 정장 한 벌 필요할 듯\n",
      "Pred: 귀 즘 하지만세 하지만 수예아요.\n",
      "Label: 사면 요긴하긴 할 거 같아요.\n",
      "epoch: 9, loss: 0.8278986215591431\n",
      "Q: 헤어진지 43일\n",
      "Pred: 를를 아요 건 어 더 힘들 거요을이에요.\n",
      "Label: 하루 하루를 헤아리는 건 자신을 더 힘들게 만들 뿐이에요.\n",
      "epoch: 9, loss: 0.7693933844566345\n",
      "Q: 짝남이 다른 애 좋아하는 것 같아.\n",
      "Pred: 럴 인실 거는 천히 하이가해봐해세어요.\n",
      "Label: 그게 확실하다면 천천히 마음의 준비가 필요하겠어요.\n",
      "epoch: 9, loss: 0.7700725793838501\n",
      "Q: 일을 나만 해\n",
      "Pred: 찍명미 기 거이보세요.\n",
      "Label: 일 분배를 다시 요청해보세요.\n",
      "epoch: 9, train_loss: 0.7337721179345411\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   9%|9         | 9/100 [1:16:43<12:59:01, 513.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 제 친구가 술마시면서 잊으려고\n",
      "Pred: 별은 들이는 것도 중요해보.\n",
      "Label: 이별을 받아들이는 것도 중요해요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 9, val_loss: 0.8096524445634139\n",
      "\n",
      "********** epoch10 train start **********\n",
      "epoch: 10, loss: 0.7261365652084351\n",
      "Q: 헤어진지 3개월이 지났네.\n",
      "Pred: 보다 많은 시간이네켜네요.\n",
      "Label: 생각보다 많은 시간이 지났네요.\n",
      "epoch: 10, loss: 0.6632766127586365\n",
      "Q: 나 천재 같아\n",
      "Pred: 저가 있 다르 있요 다을요.\n",
      "Label: 제가 따라가려면 멀었네요.\n",
      "epoch: 10, loss: 0.8612069487571716\n",
      "Q: 내일 친구랑 놀까?\n",
      "Pred: 이으면에 있을어보세요.\n",
      "Label: 시간 있냐고 물어보세요.\n",
      "epoch: 10, loss: 0.7097777724266052\n",
      "Q: 손톱이나 짧게 깎아야지\n",
      "Pred: 을든 가 하세요.\n",
      "Label: 생각났을 때 바로 하세요.\n",
      "epoch: 10, train_loss: 0.7072542616707123\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  10%|#         | 10/100 [1:25:09<12:46:55, 511.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 썸 타는 사람 생일이야. 선물 사야 해?\n",
      "Pred: 에게 물담스 것지물이 요.\n",
      "Label: 서로에게 부담 없는 작은 선물이 좋아요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 10, val_loss: 0.7883951632600081\n",
      "\n",
      "********** epoch11 train start **********\n",
      "epoch: 11, loss: 0.6420178413391113\n",
      "Q: 인관관계 맺는 게 피곤해\n",
      "Pred: 럴  에너지를 공급려고까요.\n",
      "Label: 그 사람을 위해 에너지를 쓰니까요.\n",
      "epoch: 11, loss: 0.6267116069793701\n",
      "Q: 너무 기빨려\n",
      "Pred: 잘  시간실나봐요.\n",
      "Label: 너무 긴장했나봐요.\n",
      "epoch: 11, loss: 0.6152784824371338\n",
      "Q: 졸업식에 가도 될까\n",
      "Pred: 마음가도 따라보 하죠요세요.\n",
      "Label: 졸업식에 가서 축하해주세요.\n",
      "epoch: 11, loss: 0.7355420589447021\n",
      "Q: 사랑을 표현해줬으면 좋겠어\n",
      "Pred: 사랑하는주라 말해보세요.\n",
      "Label: 표현해 달라고 말해보세요.\n",
      "epoch: 11, train_loss: 0.6820031654335068\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  11%|#1        | 11/100 [1:33:34<12:35:36, 509.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 생일축하했다 바보야\n",
      "Pred: 가길지도 하겠요세요.\n",
      "Label: 제 생일도 축하해 주세요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 11, val_loss: 0.7734223949281793\n",
      "\n",
      "********** epoch12 train start **********\n",
      "epoch: 12, loss: 0.671800971031189\n",
      "Q: 이별통보를 받았습니다\n",
      "Pred: 그이 준비가 없는 거데요돼까요요.\n",
      "Label: 마음의 준비가 필요했을텐데 안타까워요.\n",
      "epoch: 12, loss: 0.6956494450569153\n",
      "Q: 이제는 정리가 된 거 일까?\n",
      "Pred: 그보다 해해보세 것도 어떨까요.\n",
      "Label: 생각을 정리해 보는 건 어떨까요.\n",
      "epoch: 12, loss: 0.7195550799369812\n",
      "Q: 다시 만날 수 있을가.\n",
      "Pred: 이라지는 않는다면 별 하봐아 거 몰라요.\n",
      "Label: 달라지지 않는다면 이대로가 나을지도 몰라요.\n",
      "epoch: 12, loss: 0.6985637545585632\n",
      "Q: 올릴까 말까 하다가 조언을 얻고자 올려봅니다.\n",
      "Pred: 찾아는어요.해해보세요.\n",
      "Label: 잘 오셨어요. 말씀 해보세요.\n",
      "epoch: 12, train_loss: 0.6562494221561683\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  12%|#2        | 12/100 [1:42:16<12:32:37, 513.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 한달 다되가네\n",
      "Pred: 힘면 말.가하세라고요.\n",
      "Label: 그러게요. 어느덧 한달이에요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 12, val_loss: 0.7618372063887747\n",
      "\n",
      "********** epoch13 train start **********\n",
      "epoch: 13, loss: 0.603007972240448\n",
      "Q: 오늘도 계속 생각나네\n",
      "Pred: 그젠 그 시도럴이해 있어로 해요 거요.\n",
      "Label: 언제쯤 그분 생각에 자유로워질까요.\n",
      "epoch: 13, loss: 0.6683583855628967\n",
      "Q: 네일 할까\n",
      "Pred: 잘분이환을 해보세요.\n",
      "Label: 기분전환을 해보세요.\n",
      "epoch: 13, loss: 0.5762178897857666\n",
      "Q: 낙엽 밟는 소리 좋다\n",
      "Pred: 벼  요.\n",
      "Label: 가을이네요.\n",
      "epoch: 13, loss: 0.638579785823822\n",
      "Q: 이별 한달 후.\n",
      "Pred: 이라지는 모습을 힘았텐예요.\n",
      "Label: 달라진게 많을 거예요.\n",
      "epoch: 13, train_loss: 0.6340272315961872\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  13%|#3        | 13/100 [1:51:01<12:28:59, 516.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 한달 다되가네\n",
      "Pred: 잘게 말.덧 수세라고요.\n",
      "Label: 그러게요. 어느덧 한달이에요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 13, val_loss: 0.7508407893933748\n",
      "\n",
      "********** epoch14 train start **********\n",
      "epoch: 14, loss: 0.6307847499847412\n",
      "Q: 썸 타다 고백할 시기?\n",
      "Pred: 썸 타 힘상을 좋을.\n",
      "Label: 썸은 짧은 게 좋습니다.\n",
      "epoch: 14, loss: 0.4938230812549591\n",
      "Q: 초콜릿 만들어서 줄까?\n",
      "Pred: 하는 거예요.\n",
      "Label: 좋아할거예요.\n",
      "epoch: 14, loss: 0.689326822757721\n",
      "Q: 이거 좋아하는 거 맞나?\n",
      "Pred: 그이 좀금해요.\n",
      "Label: 상황이 궁금해요.\n",
      "epoch: 14, loss: 0.6490578055381775\n",
      "Q: 쌈은 뭐야\n",
      "Pred: 맛의고도시켜 수게어.\n",
      "Label: 썸 타다가 발전되지 못한 관계죠.\n",
      "epoch: 14, train_loss: 0.6098426528676542\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  14%|#4        | 14/100 [1:59:43<12:23:04, 518.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 너무너무너무 힘드네\n",
      "Pred: 이지로라도 있을챙정적인 거정 내덜이니다요세요.\n",
      "Label: 억지로라도 긍정적인 감정을 끄집어보세요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 14, val_loss: 0.7396144396380374\n",
      "\n",
      "********** epoch15 train start **********\n",
      "epoch: 15, loss: 0.6464462876319885\n",
      "Q: 눈이 안 떠져\n",
      "Pred: 저 쉬을 해여보세요.\n",
      "Label: 잠시 눈을 붙여보세요.\n",
      "epoch: 15, loss: 0.5845520496368408\n",
      "Q: 짝녀가 차갑게 굴면 어떻게 해요?\n",
      "Pred: 짝사랑이 게음을 이어어 건 좋이 거 같아요.\n",
      "Label: 짝사랑하는 마음을 접는게 편할 것 같아요.\n",
      "epoch: 15, loss: 0.5846742391586304\n",
      "Q: 군대 가도 기다리겠다더니\n",
      "Pred: 잘화이 그 힘 거이에날 수 있을 거예요.\n",
      "Label: 전역해서 더 좋은 사람 만날 수 있을 거예요.\n",
      "epoch: 15, loss: 0.606208860874176\n",
      "Q: 어떻게 헤어져\n",
      "Pred: 많이을 시간 하화 지 거 같아요.해세게세요해요.\n",
      "Label: 생각한대로 전하면 될 것 같아요. 상처는 주지 말아요.\n",
      "epoch: 15, train_loss: 0.5869530853397118\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  15%|#5        | 15/100 [2:08:21<12:14:12, 518.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 화장 열심히 했는데\n",
      "Pred: 그에는 우챙일기해보세요.\n",
      "Label: 다음에는 픽서를 사용해보세요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 15, val_loss: 0.7332365857927423\n",
      "\n",
      "********** epoch16 train start **********\n",
      "epoch: 16, loss: 0.5770230293273926\n",
      "Q: 믿는 게 아니었어\n",
      "Pred: 그 번더라고다 주세요.\n",
      "Label: 한번더 기회를 주세요.\n",
      "epoch: 16, loss: 0.5687732100486755\n",
      "Q: 지방 와서 친구가 없어\n",
      "Pred: 친구구를 사귀는보세요.\n",
      "Label: 친구를 사귀어 보세요.\n",
      "epoch: 16, loss: 0.4879266917705536\n",
      "Q: 나 잘생겼지?\n",
      "Pred: 잘 말 많을요.\n",
      "Label: 네 잘생겼어요.\n",
      "epoch: 16, loss: 0.5736287832260132\n",
      "Q: 오늘은 2년전 그녀에게 고백했던날\n",
      "Pred: 프을 아주보 라 생각게 어요.\n",
      "Label: 아픔을 헤아려도 달라지는 건 없어요.\n",
      "epoch: 16, train_loss: 0.5634765291285372\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  16%|#6        | 16/100 [2:17:01<12:06:06, 518.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 짝녀한테 고백했는데 잘 됐으면.\n",
      "Pred: 할 거예 생각어요.\n",
      "Label: 잘 될거라 믿어요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 16, val_loss: 0.7202942810560528\n",
      "\n",
      "********** epoch17 train start **********\n",
      "epoch: 17, loss: 0.507139265537262\n",
      "Q: 파란 하늘이 그리워\n",
      "Pred: 마음벼은늘을 세요.\n",
      "Label: 가끔 하늘을 보세요.\n",
      "epoch: 17, loss: 0.5992227792739868\n",
      "Q: 필기구 안가져 왔다.\n",
      "Pred: 그리 떨 돼요.\n",
      "Label: 빌리면 돼요.\n",
      "epoch: 17, loss: 0.5380889773368835\n",
      "Q: 어떤 남자애가 나 내일 뭐하냐는데 뭐라하지?\n",
      "Pred: 당  연이을고니 노력도해보세요.\n",
      "Label: 너랑 약속잡으려고 한다고 말해보세요.\n",
      "epoch: 17, loss: 0.5199594497680664\n",
      "Q: 이런게 후폭풍인가.\n",
      "Pred: 후회풍이 수도 있을요.\n",
      "Label: 후폭풍일 수 있지요.\n",
      "epoch: 17, train_loss: 0.5396276876598061\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  17%|#7        | 17/100 [2:25:36<11:55:59, 517.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 에휴 후폭풍인가봐\n",
      "Pred: 별은  못련를이죠요.\n",
      "Label: 이별에는 항상 후유증이 있어요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 17, val_loss: 0.7165909378152144\n",
      "\n",
      "********** epoch18 train start **********\n",
      "epoch: 18, loss: 0.5214620232582092\n",
      "Q: 남자친구의 과거 어디까지 이해해?\n",
      "Pred: 후예 처음주 싶말 게 좋할가예아요.\n",
      "Label: 아예 알려고 하지 않는 게 편한 거 같아요.\n",
      "epoch: 18, loss: 0.5014276504516602\n",
      "Q: 오늘 헤어졌어여\n",
      "Pred: 힘 더괜찮아 거봐.\n",
      "Label: 좀 괜찮은가요.\n",
      "epoch: 18, loss: 0.5011196732521057\n",
      "Q: 3년 째 트라우마\n",
      "Pred: 처받 마음에지어보지 어요.\n",
      "Label: 상처받은 마음 보듬어주고 싶네요.\n",
      "epoch: 18, loss: 0.5437368750572205\n",
      "Q: 혼수 얼마야?\n",
      "Pred: 혼마다다 다르라요.\n",
      "Label: 사람 마다 달라요.\n",
      "epoch: 18, train_loss: 0.5156125379893595\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  18%|#8        | 18/100 [2:33:50<11:37:42, 510.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 엄마가 선 보라고 하시는데\n",
      "Pred: 좋은 지보세요.\n",
      "Label: 많이 만나보세요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 18, val_loss: 0.7086800430950365\n",
      "\n",
      "********** epoch19 train start **********\n",
      "epoch: 19, loss: 0.46209660172462463\n",
      "Q: 연금 받을 수 있을까\n",
      "Pred: 연 것보다 나을 거예요.\n",
      "Label: 없는 것보다 나을 거예요.\n",
      "epoch: 19, loss: 0.5777795314788818\n",
      "Q: 여자친구의 이성친구가 고민이야.\n",
      "Pred: 고날 수를 가세요.\n",
      "Label: 만날 때 같이 만나세요.\n",
      "epoch: 19, loss: 0.49524933099746704\n",
      "Q: 남친 있는데 다른 사람이 자꾸 눈에 들어와.\n",
      "Pred: 이방이 헷갈리게요건 좋겠 않아요.\n",
      "Label: 상대방을 헷갈리게 하는건 좋지 않아요.\n",
      "epoch: 19, loss: 0.47603535652160645\n",
      "Q: 만나면 좋은데 사귀긴 싫어\n",
      "Pred: 사랑사람친구나 여자인람친구나세요.\n",
      "Label: 남자사람친구, 여자사람친구 하세요.\n",
      "epoch: 19, train_loss: 0.490573217768869\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  19%|#9        | 19/100 [2:42:35<11:35:14, 514.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 썸남 있는데 완전 스윗함.\n",
      "Pred: 여서세면네요.\n",
      "Label: 녹아내리겠네요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 19, val_loss: 0.6959522931199325\n",
      "\n",
      "********** epoch20 train start **********\n",
      "epoch: 20, loss: 0.5146181583404541\n",
      "Q: 돈 굴리기\n",
      "Pred: 저도요 알려주세요.\n",
      "Label: 저도 좀 알려주세요.\n",
      "epoch: 20, loss: 0.5148715376853943\n",
      "Q: 도서관 책 반납 안햇다\n",
      "Pred: 저맛먹기나봐요.\n",
      "Label: 까먹었나봐요.\n",
      "epoch: 20, loss: 0.4584040939807892\n",
      "Q: 아침에 들을 노래 추천해줘\n",
      "Pred: 정의한요.\n",
      "Label: 애국가요.\n",
      "epoch: 20, loss: 0.40265074372291565\n",
      "Q: 투잡할까?\n",
      "Pred: 저고요.\n",
      "Label: 가능하다면요.\n",
      "epoch: 20, train_loss: 0.46457011096491785\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  20%|##        | 20/100 [2:51:18<11:29:39, 517.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  ⁇  앞에만 서면 말이 안 나와\n",
      "Pred: 마음슨 마음 해 수 마락해보세요.\n",
      "Label: 무슨 말을 할지 연습해보세요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 20, val_loss: 0.6954089497265062\n",
      "\n",
      "********** epoch21 train start **********\n",
      "epoch: 21, loss: 0.5149469375610352\n",
      "Q: 짝사랑 하는 여자 때문에 신경이 곤두서.\n",
      "Pred: 맘같지 마서 가봐요.\n",
      "Label: 내 맘같지 않아서 그런가봐요.\n",
      "epoch: 21, loss: 0.4551154673099518\n",
      "Q: 할말 다 했는데 실수한건가\n",
      "Pred: 당에게 피해만 주지 마면 좋관 없어요.\n",
      "Label: 남에게 피해만 주지 않는다면 상관 없어요.\n",
      "epoch: 21, loss: 0.41158396005630493\n",
      "Q: 방금도 엉엉 울었네\n",
      "Pred: 그 좋은어도 돼요.\n",
      "Label: 더 울어도 돼요.\n",
      "epoch: 21, loss: 0.4277487099170685\n",
      "Q: 오랜연애 환승이별\n",
      "Pred: 사랑의 예의가 없네요.\n",
      "Label: 사랑의 예의가 없네요.\n",
      "epoch: 21, train_loss: 0.4395685840152695\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  21%|##1       | 21/100 [3:00:21<11:31:07, 524.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 꽃 예쁘게 말렸어\n",
      "Pred: 제뭐는가 다죠니길요.\n",
      "Label: 솜씨가 좋으시네요.\n",
      "epoch: 21, val_loss: 0.6961024529055545\n",
      "\n",
      "********** epoch22 train start **********\n",
      "epoch: 22, loss: 0.40557414293289185\n",
      "Q: 차별받고 있는 느낌\n",
      "Pred: 이별을 안니 다했 건요요.\n",
      "Label: 차별을 하다니 못난 사람들이군요.\n",
      "epoch: 22, loss: 0.40555670857429504\n",
      "Q: 그는 나를 어떻게 생각할까?\n",
      "Pred: 그쎄요.\n",
      "Label: 글쎄요.\n",
      "epoch: 22, loss: 0.4463749825954437\n",
      "Q: 남친 생겼는데 호칭 어떻게 해?\n",
      "Pred: 잘짝 좋 될오는 게 수도 만들어보세요.\n",
      "Label: 딱 보면 떠오르는 걸로 해보세요.\n",
      "epoch: 22, loss: 0.46626269817352295\n",
      "Q: 변명거리가 생각이 안나\n",
      "Pred: 명보다는 포장이 좋죠 거 같아요.\n",
      "Label: 변명보다는 포장이 좋을 것 같아요.\n",
      "epoch: 22, train_loss: 0.4140753060757757\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  22%|##2       | 22/100 [3:41:19<23:56:49, 1105.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 너무너무너무 힘드네\n",
      "Pred: 힘지로라도 잊정적인 변화정 내걱기니다요세요.\n",
      "Label: 억지로라도 긍정적인 감정을 끄집어보세요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 22, val_loss: 0.6937611573620847\n",
      "\n",
      "********** epoch23 train start **********\n",
      "epoch: 23, loss: 0.33437255024909973\n",
      "Q: 김치찌개 먹고 싶어\n",
      "Pred: 맛있게.\n",
      "Label: 맛있죠!\n",
      "epoch: 23, loss: 0.41183874011039734\n",
      "Q: 아울렛 가서 쇼핑하고 옴\n",
      "Pred: 마음핑 아 항상프렛이죠.\n",
      "Label: 쇼핑은 아울렛이죠.\n",
      "epoch: 23, loss: 0.3376278579235077\n",
      "Q: 크리스마스엔 눈이 올까\n",
      "Pred: 저이네면 좋겠네요.\n",
      "Label: 눈이 오면 좋겠네요.\n",
      "epoch: 23, loss: 0.34091007709503174\n",
      "Q: 눈이 안 떠져\n",
      "Pred: 눈 눈을 붙여보세요.\n",
      "Label: 잠시 눈을 붙여보세요.\n",
      "epoch: 23, train_loss: 0.38920337943259825\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  23%|##3       | 23/100 [4:08:09<26:52:42, 1256.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 4년째 짝사랑 중인 나 이제 고백해도 될까?\n",
      "Pred: 회없 것 자은백하는 있해보덜요.\n",
      "Label: 후회하는 것 보다 고백하고 생각해 봐요.\n",
      "\n",
      "****best model saved****\n",
      "\n",
      "epoch: 23, val_loss: 0.6875785495105543\n",
      "\n",
      "********** epoch24 train start **********\n",
      "epoch: 24, loss: 0.280789315700531\n",
      "Q: 짝녀한테 문자 왔어.\n",
      "Pred: 짝라도요했나지요금하요.\n",
      "Label: 뭐라고 했는지 궁금해요.\n",
      "epoch: 24, loss: 0.3781311511993408\n",
      "Q: 싸우면 연락이 안돼\n",
      "Pred: 자 풀릴 때까지 놔둬야하는데 기다려게 좋아들 거예요.\n",
      "Label: 혼자 풀릴 때까지 놔둬야하는데 기다리는게 힘들 거예요.\n",
      "epoch: 24, loss: 0.44390052556991577\n",
      "Q: 마음이 조급해\n",
      "Pred: 마음에 복잡급해지면  마 때수를 하게 돼요.\n",
      "Label: 마음이 조급해지면 하지 않을 실수를 하게 돼요.\n",
      "epoch: 24, loss: 0.4367803931236267\n",
      "Q: 화이트데이에 뭐 선물하지\n",
      "Pred: 부탕 만들어요.\n",
      "Label: 사탕 만들어요.\n",
      "epoch: 24, train_loss: 0.3643514817346356\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  24%|##4       | 24/100 [4:17:23<22:04:51, 1045.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 썸 타는 사람 생일이야. 선물 사야 해?\n",
      "Pred: 연 공 바담스걸것물이 좋요.\n",
      "Label: 서로에게 부담 없는 작은 선물이 좋아요.\n",
      "epoch: 24, val_loss: 0.700674078966442\n",
      "\n",
      "********** epoch25 train start **********\n",
      "epoch: 25, loss: 0.30486536026000977\n",
      "Q: 비밀로 했는데 들켜서 오해하고 있어\n",
      "Pred: 회원해가만큼 일이 생겼네 거는 건직해 생각해 있어어보세요.\n",
      "Label: 오해할만한 일이 생겼을때는 솔직하게 이야기하고 풀어보세요.\n",
      "epoch: 25, loss: 0.34959229826927185\n",
      "Q: 나랑 사귈래?\n",
      "Pred: 도 괜찮다면 거요.\n",
      "Label: 저라도 괜찮다면 좋아요.\n",
      "epoch: 25, loss: 0.32062897086143494\n",
      "Q: 드라마같은 사랑 하고 싶어\n",
      "Pred: 사랑는 현실과 같요 믿.\n",
      "Label: 드라마는 현실과 달라요.\n",
      "epoch: 25, loss: 0.40403130650520325\n",
      "Q: 짝사랑은 힘든 거 같아\n",
      "Pred: 사랑도 좋아하는 거 행복하세 바라요.\n",
      "Label: 그래도 좋아하는 동안 행복하길 바라요.\n",
      "epoch: 25, train_loss: 0.3394200085344429\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  25%|##5       | 25/100 [4:26:16<18:35:01, 892.02s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 헉\n",
      "Pred: 저 수나요\n",
      "Label: 놀랐나봐요.\n",
      "epoch: 25, val_loss: 0.6935852734666121\n",
      "\n",
      "********** epoch26 train start **********\n",
      "epoch: 26, loss: 0.31951022148132324\n",
      "Q: 추억. 그 미칠듯한 그리움.\n",
      "Pred: 추억은 미화되기 마련이네.\n",
      "Label: 추억은 미화되기 마련이죠.\n",
      "epoch: 26, loss: 0.31879112124443054\n",
      "Q: 쫄면 생각나\n",
      "Pred: 른 요리하면보세요.\n",
      "Label: 얼른 요리해드세요.\n",
      "epoch: 26, loss: 0.3251132071018219\n",
      "Q: 이별 하루차를 보내고 있습니다\n",
      "Pred: 익소하지지 쉽하고 싶할세요.\n",
      "Label: 평상시처럼 생활하고 행동하세요.\n",
      "epoch: 26, loss: 0.39564451575279236\n",
      "Q: 같이 먹었는데 나만 살찐 거 같아\n",
      "Pred: 즐인은 살쪄도 하는차리지 못하고 알아차려보 맛어보 마 거예요.\n",
      "Label: 연인은 살쪄도 잘 알아차리지 못하고 알아차려도 싫어하지 않을 거예요.\n",
      "epoch: 26, train_loss: 0.3152204709138699\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  26%|##6       | 26/100 [4:35:16<16:09:39, 786.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 갑자기 나쁜 생각이 막 들더라\n",
      "Pred: 인 생각이에 하세요.\n",
      "Label: 좋은 생각만 하세요.\n",
      "epoch: 26, val_loss: 0.6956548941762823\n",
      "\n",
      "********** epoch27 train start **********\n",
      "epoch: 27, loss: 0.27064570784568787\n",
      "Q: 외롭지만 혼자 걸을수 있어_조성모\n",
      "Pred: 혼가 있에서 벗켜보릴게요.\n",
      "Label: 제가 뒤에서 지켜드릴게요.\n",
      "epoch: 27, loss: 0.2650649845600128\n",
      "Q: 참 허무하네.\n",
      "Pred: 마음이 전한가봐요.\n",
      "Label: 마음이 허전한가봐요.\n",
      "epoch: 27, loss: 0.20975948870182037\n",
      "Q: 메모리카드 잃어버렸어\n",
      "Pred: 오늘이 달렸나봐요.\n",
      "Label: 발이 달렸나봐요.\n",
      "epoch: 27, loss: 0.3268261253833771\n",
      "Q: 이별이 있어야 인연도 있는거 같아.\n",
      "Pred: 이별은 가장 시작이 안길 하니까요.\n",
      "Label: 이별이 새로운 시작이 되기도 하니까요.\n",
      "epoch: 27, train_loss: 0.29134316795957305\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  27%|##7       | 27/100 [4:44:14<14:25:54, 711.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 조명빨인가\n",
      "Pred: 저멋진요요.\n",
      "Label: 멋져 보여요!\n",
      "epoch: 27, val_loss: 0.7016775764917073\n",
      "\n",
      "********** epoch28 train start **********\n",
      "epoch: 28, loss: 0.28134217858314514\n",
      "Q: 비가오네\n",
      "Pred: 우 걱추하예요.\n",
      "Label: 그리고 멈출 거예요.\n",
      "epoch: 28, loss: 0.27308496832847595\n",
      "Q: 썸타는 중인데 계속 먼저 연락해도 됨?\n",
      "Pred: 연담스럽지 않은 선이 좋겠어요.\n",
      "Label: 부담스럽지 않은 선이 좋겠어요.\n",
      "epoch: 28, loss: 0.23708003759384155\n",
      "Q: 결국 연락을 해버렸네.\n",
      "Pred: 연할셨어요.\n",
      "Label: 잘하셨어요.\n",
      "epoch: 28, loss: 0.275409072637558\n",
      "Q: 단체생활 많이 힘든가\n",
      "Pred: 서로 마음려해야 하니까요.\n",
      "Label: 서로 배려해야 하니까요.\n",
      "epoch: 28, train_loss: 0.26935131651555705\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  28%|##8       | 28/100 [4:53:20<13:14:23, 661.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 제 친구가 술마시면서 잊으려고\n",
      "Pred: 친구별이 받아들이는 것도 중요해요.\n",
      "Label: 이별을 받아들이는 것도 중요해요.\n",
      "epoch: 28, val_loss: 0.705417369541369\n",
      "\n",
      "********** epoch29 train start **********\n",
      "epoch: 29, loss: 0.23165363073349\n",
      "Q: 분위기 좋은 곳에서 데이트하고 싶어\n",
      "Pred: 매일 볼고 싶네요.\n",
      "Label: 매일 가고 싶네요.\n",
      "epoch: 29, loss: 0.22819818556308746\n",
      "Q: 농담처럼 진담하는 사람\n",
      "Pred: 똑같이 해야세요.\n",
      "Label: 똑같이 해주세요.\n",
      "epoch: 29, loss: 0.2196212112903595\n",
      "Q: 넌 행복하네\n",
      "Pred: 당신도 행복한세요.\n",
      "Label: 당신도 행복하세요.\n",
      "epoch: 29, loss: 0.21382072567939758\n",
      "Q: 나 친구들한테 인정받고 싶어\n",
      "Pred: 지금도 받고 있어요.\n",
      "Label: 지금도 인정받고 있어요.\n",
      "epoch: 29, train_loss: 0.24641885452284784\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  29%|##9       | 29/100 [5:02:26<12:22:12, 627.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 엄마가 선 보라고 하시는데\n",
      "Pred: 엄 피보세요.\n",
      "Label: 많이 만나보세요.\n",
      "epoch: 29, val_loss: 0.7088711638199655\n",
      "\n",
      "********** epoch30 train start **********\n",
      "epoch: 30, loss: 0.22142039239406586\n",
      "Q: 내가 뭘 잘못했을까\n",
      "Pred: 모르는 게 잘못인 거 같아요.\n",
      "Label: 모르는 게 잘못인 거 같아요.\n",
      "epoch: 30, loss: 0.19435279071331024\n",
      "Q: 아무리 생각 안하려 해도\n",
      "Pred: 그치가에 비물하기도 해요.\n",
      "Label: 눈 앞에 선연하기도 해요.\n",
      "epoch: 30, loss: 0.24812480807304382\n",
      "Q: 이별후폭풍 왜이렇게 심하죠\n",
      "Pred: 건강별은 언처를 남겨드 그런덤봐 것이트게이 될예 거예요.\n",
      "Label: 이별은 상처를 남겨서 무뎌지는 데는 시간이 거릴 거예요.\n",
      "epoch: 30, loss: 0.21111825108528137\n",
      "Q: 주말인데 연락해볼까?\n",
      "Pred: 거른 주락해보세요.\n",
      "Label: 얼른 연락해보세요.\n",
      "epoch: 30, train_loss: 0.22602584520856778\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  30%|###       | 30/100 [5:11:19<11:38:46, 598.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 한달 다되가네\n",
      "Pred: 생각게 말. 생각덧 일 건았요.\n",
      "Label: 그러게요. 어느덧 한달이에요.\n",
      "epoch: 30, val_loss: 0.7228733552129645\n",
      "\n",
      "********** epoch31 train start **********\n",
      "epoch: 31, loss: 0.1502198576927185\n",
      "Q: 정말 아직 너무 사랑합니다 잡고 싶습니다\n",
      "Pred: 다시 잡는다면 후회할 거예요.\n",
      "Label: 다시 잡는다면 후회할 거예요.\n",
      "epoch: 31, loss: 0.15972517430782318\n",
      "Q: 셀카 좀 잘 찍고 싶다\n",
      "Pred: 연습해보세요.\n",
      "Label: 연습해보세요.\n",
      "epoch: 31, loss: 0.19429582357406616\n",
      "Q: 영화보고 왔다\n",
      "Pred: 저도 영화 보여주세요.\n",
      "Label: 저도 영화 보여주세요.\n",
      "epoch: 31, loss: 0.22896885871887207\n",
      "Q: 썸 끝나고 잡아도 될까\n",
      "Pred: 좋아은 언제 타 상 시작해도 늦니다.\n",
      "Label: 사랑은 언제든 다시 시작해도 됩니다.\n",
      "epoch: 31, train_loss: 0.20631861213795438\n",
      "********** train end **********\n",
      "\n",
      "********** eval start **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  31%|###1      | 31/100 [5:20:22<11:09:31, 582.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 진심일까\n",
      "Pred: 너무 물어보세요.\n",
      "Label: 직접 물어보세요.\n",
      "epoch: 31, val_loss: 0.7326420953399256\n",
      "\n",
      "********** epoch32 train start **********\n",
      "epoch: 32, loss: 0.18364588916301727\n",
      "Q: 여자친구가 계획적이지 않아서 스트레스 받아.\n",
      "Pred: 성격도이니 받아들여야세요.\n",
      "Label: 성격 차이니 받아들여보세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  31%|###1      | 31/100 [5:22:31<11:57:52, 624.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./weight/best_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 62\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loss_fn, optimizer, save_path, eval_step, resume, run_id)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# 역전파 및 최적화\u001b[39;00m\n\u001b[1;32m     61\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 62\u001b[0m \u001b[43mavg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(train_dataloader)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-summer/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-summer/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-summer/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_path = f'./weight/best_{model_name}.pt'\n",
    "train(loss_fn, optimizer,save_path, eval_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 잘 안되네\n",
      "출력 문장: 때\n"
     ]
    }
   ],
   "source": [
    "#저장된 best 가중치 불러오기\n",
    "model = Transformer(n_seq, n_vocab, n_dim, n_head, n_layer, device=device).to(device)\n",
    "save_path = f'./weight/best_{model_name}.pt'\n",
    "state_dict = torch.load(save_path)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "prompt = \"잘 안되네\"\n",
    "output = generate_sentc(model, sp, n_seq, prompt, device)\n",
    "print(\"입력 문장:\", prompt)\n",
    "print(\"출력 문장:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
